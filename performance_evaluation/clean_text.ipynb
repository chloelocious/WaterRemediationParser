{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Open the JSON file and load the data\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/qa_format_output3.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Replace \"\\p\" with \"\\\\\" to match a literal backslash\n",
    "regex = r'https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+'\n",
    "\n",
    "# Apply the regex to each string value in the JSON data\n",
    "for i in range(len(data)):\n",
    "    if isinstance(data[i], str):\n",
    "        data[i] = re.sub(regex, \"\", data[i])\n",
    "    elif isinstance(data[i], dict):\n",
    "        for key in data[i]:\n",
    "            if isinstance(data[i][key], str):\n",
    "                data[i][key] = re.sub(regex, \"\", data[i][key])\n",
    "\n",
    "# Save the cleaned data back to the same JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/qa_format_output3.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if isinstance(data[i], str):\n",
    "        # Replace all occurrences of \\n with an empty string\n",
    "        data[i] = data[i].replace('\\n', '')\n",
    "    elif isinstance(data[i], dict):\n",
    "        for key in data[i]:\n",
    "            if isinstance(data[i][key], str):\n",
    "                # Replace all occurrences of \\n with an empty string\n",
    "                data[i][key] = data[i][key].replace('\\n', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/qa_format_output3.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Remove all occurrences of \\n from string values in the data\n",
    "for i in range(len(data)):\n",
    "    if isinstance(data[i], str):\n",
    "        data[i] = data[i].replace('\\n', '')\n",
    "    elif isinstance(data[i], dict):\n",
    "        for key in data[i]:\n",
    "            if isinstance(data[i][key], str):\n",
    "                data[i][key] = data[i][key].replace('\\n', '')\n",
    "\n",
    "# Save the modified data back to the same JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/qa_format_output3.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "# specify the directory path to the text files\n",
    "dir_path = \"/home/ssarrouf/Documents/test_data_2\"\n",
    "\n",
    "# loop through each file in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        # read the file contents\n",
    "        with open(os.path.join(dir_path, filename), \"r\") as f:\n",
    "            text = f.read()\n",
    "        # remove unicode characters\n",
    "        text = text.replace('\\n', '')\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "        # overwrite the file with the cleaned text\n",
    "        with open(os.path.join(dir_path, filename), \"w\") as f:\n",
    "            f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load your data from a file\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/finetune_qa_good_results.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert your data to the SQuAD format\n",
    "squad_data = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"context\": d[\"context\"],\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"question\": d[\"question\"],\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": d[\"answer\"],\n",
    "                                    \"answer_start\": d[\"context\"].find(d[\"answer\"])\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        } for d in data\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save the converted data to a file\n",
    "with open(\"squad_finetune_qa_good_results.json\", \"w\") as f:\n",
    "    json.dump(squad_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def assign_ids(dataset):\n",
    "    for i, d in enumerate(dataset['data']):\n",
    "        for j, p in enumerate(d['paragraphs']):\n",
    "            dataset['data'][i]['paragraphs'][j]['id'] = f\"{i}_{j}\"\n",
    "    return dataset\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/squad_finetune_qa_generated_results.json\", \"r\") as f:\n",
    "    dataset1 = json.load(f)\n",
    "\n",
    "# Assign unique IDs to each context in the first JSON file\n",
    "dataset1 = assign_ids(dataset1)\n",
    "\n",
    "# Load the second JSON file\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/squad_finetune_qa_good_results.json\", \"r\") as f:\n",
    "    dataset2 = json.load(f)\n",
    "\n",
    "# Assign unique IDs to each context in the second JSON file, matching the ID with the corresponding context in the first JSON file\n",
    "for i, d in enumerate(dataset2['data']):\n",
    "    for j, p in enumerate(d['paragraphs']):\n",
    "        context = dataset2['data'][i]['paragraphs'][j]['context']\n",
    "        for k, dp in enumerate(dataset1['data']):\n",
    "            for l, pp in enumerate(dp['paragraphs']):\n",
    "                if pp['context'] == context:\n",
    "                    dataset2['data'][i]['paragraphs'][j]['id'] = f\"{k}_{l}\"\n",
    "                    break\n",
    "\n",
    "# Save the updated JSON files\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/squad_finetune_qa_generated_results.json\", \"w\") as f:\n",
    "    json.dump(dataset1, f)\n",
    "\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/squad_finetune_qa_good_results.json\", \"w\") as f:\n",
    "    json.dump(dataset2, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/squad_finetune_qa_generated_results.json\", \"r\") as f1, open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/squad_finetune_qa_good_results.json\", \"r\") as f2:\n",
    "    data1 = json.load(f1)\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "# Create a set of all contexts in data1\n",
    "contexts1 = {p['context'] for d in data1['data'] for p in d['paragraphs']}\n",
    "\n",
    "# Create a set of all contexts in data2\n",
    "contexts2 = {p['context'] for d in data2['data'] for p in d['paragraphs']}\n",
    "\n",
    "# Find the contexts in data1 that are not in data2\n",
    "missing_contexts = contexts1 - contexts2\n",
    "\n",
    "# Print the missing contexts\n",
    "for context in missing_contexts:\n",
    "    print(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def write_json_file(data, filepath):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def generate_qa_pairs(data):\n",
    "    qa_pairs = []\n",
    "    for paragraph in data['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            question = qa['question']\n",
    "            answer = qa['answers'][0]['text']\n",
    "            qa_id = qa['id']\n",
    "            qa_pairs.append((context, question, answer, qa_id))\n",
    "    return qa_pairs\n",
    "\n",
    "def update_ids(qa_pairs, qa_id_map):\n",
    "    for qa in qa_pairs:\n",
    "        old_qa_id = qa[3]\n",
    "        new_qa_id = qa_id_map[str(old_qa_id)]\n",
    "        qa_id_map[str(old_qa_id)] = new_qa_id\n",
    "        qa[3] = new_qa_id\n",
    "\n",
    "def main():\n",
    "    filepath1 = '/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json'\n",
    "    filepath2 = '/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json'\n",
    "    data1 = read_json_file(filepath1)\n",
    "    print(data1.keys())\n",
    "    data2 = read_json_file(filepath2)\n",
    "    print(data2.keys())\n",
    "    qa_pairs1 = generate_qa_pairs(data1)\n",
    "    qa_pairs2 = generate_qa_pairs(data2)\n",
    "    qa_id_map = {}\n",
    "    for i, qa in enumerate(qa_pairs1 + qa_pairs2):\n",
    "        qa_id_map[str(qa[3])] = i\n",
    "    update_ids(qa_pairs1, qa_id_map)\n",
    "    update_ids(qa_pairs2, qa_id_map)\n",
    "    write_json_file(data1, filepath1)\n",
    "    write_json_file(data2, filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def write_json_file(data, filepath):\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def generate_qa_pairs(data):\n",
    "    qa_pairs = []\n",
    "    for paragraph in data['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            qa['id'] = None  # Clear the ID\n",
    "            question = qa['question']\n",
    "            answer = qa['answers'][0]['text']\n",
    "            qa_pairs.append((context, question, answer, None))\n",
    "    return qa_pairs\n",
    "\n",
    "\n",
    "def update_ids(qa_pairs, qa_id_map):\n",
    "    for qa in qa_pairs:\n",
    "        context_id, question, old_qa_id = qa[0], qa[2], qa[4] # modified\n",
    "        new_qa_id = qa_id_map.get((context_id, question, old_qa_id), len(qa_id_map))\n",
    "        qa_id_map[(context_id, question, old_qa_id)] = new_qa_id\n",
    "        qa[4] = new_qa_id\n",
    "\n",
    "def main():\n",
    "    filepath1 = '/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json'\n",
    "    filepath2 = '/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json'\n",
    "    data1 = read_json_file(filepath1)\n",
    "    print(data1.keys())\n",
    "    data2 = read_json_file(filepath2)\n",
    "    print(data2.keys())\n",
    "    qa_pairs1 = generate_qa_pairs(data1)\n",
    "    qa_pairs2 = generate_qa_pairs(data2)\n",
    "    qa_id_map = {}\n",
    "    for i, qa in enumerate(qa_pairs1 + qa_pairs2):\n",
    "        context_id, question, qa_id = qa[0], qa[2], qa[4] # modified\n",
    "        qa_id_map[(context_id, question, qa_id)] = i # modified\n",
    "    update_ids(qa_pairs1, qa_id_map)\n",
    "    update_ids(qa_pairs2, qa_id_map)\n",
    "    write_json_file(data1, filepath1)\n",
    "    write_json_file(data2, filepath2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the first JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "# Load the second JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# Loop through the paragraphs of the first JSON file\n",
    "for p1 in data1['data'][0]['paragraphs']:\n",
    "    context1 = p1['context']\n",
    "    qas1 = p1['qas']\n",
    "\n",
    "    # Loop through the qas of the first JSON file\n",
    "    for qa1 in qas1:\n",
    "        question1 = qa1['question']\n",
    "        id1 = qa1['id']\n",
    "\n",
    "        # Loop through the paragraphs of the second JSON file\n",
    "        for p2 in data2['data'][0]['paragraphs']:\n",
    "            context2 = p2['context']\n",
    "            qas2 = p2['qas']\n",
    "\n",
    "            # Check if the contexts match\n",
    "            if context1 == context2:\n",
    "                # Loop through the qas of the second JSON file\n",
    "                for qa2 in qas2:\n",
    "                    question2 = qa2['question']\n",
    "\n",
    "                    # Check if the questions match\n",
    "                    if question1 == question2:\n",
    "                        qa2['id'] = id1\n",
    "\n",
    "# Save the updated second JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json', 'w') as f:\n",
    "    json.dump(data2, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"exact_match\": 0.0, \"f1\": 0.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation expects v-1.1, but got dataset with v-v-1.1\n",
      "Unanswered question 1 will receive score 0.\n",
      "Unanswered question 2 will receive score 0.\n",
      "Unanswered question 3 will receive score 0.\n",
      "Unanswered question 4 will receive score 0.\n",
      "Unanswered question 5 will receive score 0.\n",
      "Unanswered question 6 will receive score 0.\n",
      "Unanswered question 7 will receive score 0.\n",
      "Unanswered question 8 will receive score 0.\n",
      "Unanswered question 9 will receive score 0.\n",
      "Unanswered question 10 will receive score 0.\n",
      "Unanswered question 11 will receive score 0.\n",
      "Unanswered question 12 will receive score 0.\n",
      "Unanswered question 13 will receive score 0.\n",
      "Unanswered question 14 will receive score 0.\n",
      "Unanswered question 15 will receive score 0.\n",
      "Unanswered question 16 will receive score 0.\n",
      "Unanswered question 17 will receive score 0.\n",
      "Unanswered question 18 will receive score 0.\n",
      "Unanswered question 19 will receive score 0.\n",
      "Unanswered question 20 will receive score 0.\n",
      "Unanswered question 21 will receive score 0.\n",
      "Unanswered question 22 will receive score 0.\n",
      "Unanswered question 23 will receive score 0.\n",
      "Unanswered question 24 will receive score 0.\n",
      "Unanswered question 25 will receive score 0.\n",
      "Unanswered question 26 will receive score 0.\n",
      "Unanswered question 27 will receive score 0.\n",
      "Unanswered question 28 will receive score 0.\n",
      "Unanswered question 29 will receive score 0.\n",
      "Unanswered question 30 will receive score 0.\n",
      "Unanswered question 31 will receive score 0.\n",
      "Unanswered question 32 will receive score 0.\n",
      "Unanswered question 33 will receive score 0.\n",
      "Unanswered question 34 will receive score 0.\n",
      "Unanswered question 35 will receive score 0.\n",
      "Unanswered question 36 will receive score 0.\n",
      "Unanswered question 37 will receive score 0.\n",
      "Unanswered question 38 will receive score 0.\n",
      "Unanswered question 39 will receive score 0.\n",
      "Unanswered question 40 will receive score 0.\n",
      "Unanswered question 41 will receive score 0.\n",
      "Unanswered question 42 will receive score 0.\n",
      "Unanswered question 43 will receive score 0.\n",
      "Unanswered question 44 will receive score 0.\n",
      "Unanswered question 45 will receive score 0.\n",
      "Unanswered question 46 will receive score 0.\n",
      "Unanswered question 47 will receive score 0.\n",
      "Unanswered question 48 will receive score 0.\n",
      "Unanswered question 49 will receive score 0.\n",
      "Unanswered question 50 will receive score 0.\n",
      "Unanswered question 51 will receive score 0.\n",
      "Unanswered question 52 will receive score 0.\n",
      "Unanswered question 53 will receive score 0.\n",
      "Unanswered question 54 will receive score 0.\n",
      "Unanswered question 55 will receive score 0.\n",
      "Unanswered question 56 will receive score 0.\n",
      "Unanswered question 57 will receive score 0.\n",
      "Unanswered question 58 will receive score 0.\n",
      "Unanswered question 59 will receive score 0.\n",
      "Unanswered question 60 will receive score 0.\n",
      "Unanswered question 61 will receive score 0.\n",
      "Unanswered question 62 will receive score 0.\n",
      "Unanswered question 63 will receive score 0.\n",
      "Unanswered question 64 will receive score 0.\n",
      "Unanswered question 65 will receive score 0.\n",
      "Unanswered question 66 will receive score 0.\n",
      "Unanswered question 67 will receive score 0.\n",
      "Unanswered question 68 will receive score 0.\n",
      "Unanswered question 69 will receive score 0.\n",
      "Unanswered question 70 will receive score 0.\n",
      "Unanswered question 71 will receive score 0.\n",
      "Unanswered question 72 will receive score 0.\n",
      "Unanswered question 73 will receive score 0.\n",
      "Unanswered question 74 will receive score 0.\n",
      "Unanswered question 75 will receive score 0.\n",
      "Unanswered question 76 will receive score 0.\n",
      "Unanswered question 77 will receive score 0.\n",
      "Unanswered question 78 will receive score 0.\n",
      "Unanswered question 79 will receive score 0.\n",
      "Unanswered question 80 will receive score 0.\n",
      "Unanswered question 81 will receive score 0.\n",
      "Unanswered question 82 will receive score 0.\n",
      "Unanswered question 83 will receive score 0.\n",
      "Unanswered question 84 will receive score 0.\n",
      "Unanswered question 85 will receive score 0.\n",
      "Unanswered question 86 will receive score 0.\n",
      "Unanswered question 87 will receive score 0.\n",
      "Unanswered question 88 will receive score 0.\n",
      "Unanswered question 89 will receive score 0.\n",
      "Unanswered question 90 will receive score 0.\n",
      "Unanswered question 91 will receive score 0.\n",
      "Unanswered question 92 will receive score 0.\n",
      "Unanswered question 93 will receive score 0.\n",
      "Unanswered question 94 will receive score 0.\n",
      "Unanswered question 95 will receive score 0.\n",
      "Unanswered question 96 will receive score 0.\n",
      "Unanswered question 97 will receive score 0.\n",
      "Unanswered question 98 will receive score 0.\n",
      "Unanswered question 99 will receive score 0.\n",
      "Unanswered question 100 will receive score 0.\n",
      "Unanswered question 101 will receive score 0.\n",
      "Unanswered question 102 will receive score 0.\n",
      "Unanswered question 103 will receive score 0.\n",
      "Unanswered question 104 will receive score 0.\n",
      "Unanswered question 105 will receive score 0.\n",
      "Unanswered question 106 will receive score 0.\n",
      "Unanswered question 107 will receive score 0.\n",
      "Unanswered question 108 will receive score 0.\n",
      "Unanswered question 109 will receive score 0.\n",
      "Unanswered question 110 will receive score 0.\n",
      "Unanswered question 111 will receive score 0.\n",
      "Unanswered question 112 will receive score 0.\n",
      "Unanswered question 113 will receive score 0.\n",
      "Unanswered question 114 will receive score 0.\n",
      "Unanswered question 115 will receive score 0.\n",
      "Unanswered question 116 will receive score 0.\n",
      "Unanswered question 117 will receive score 0.\n",
      "Unanswered question 118 will receive score 0.\n",
      "Unanswered question 119 will receive score 0.\n",
      "Unanswered question 120 will receive score 0.\n",
      "Unanswered question 121 will receive score 0.\n",
      "Unanswered question 122 will receive score 0.\n",
      "Unanswered question 123 will receive score 0.\n",
      "Unanswered question 124 will receive score 0.\n",
      "Unanswered question 125 will receive score 0.\n",
      "Unanswered question 126 will receive score 0.\n",
      "Unanswered question 127 will receive score 0.\n",
      "Unanswered question 128 will receive score 0.\n",
      "Unanswered question 129 will receive score 0.\n",
      "Unanswered question 130 will receive score 0.\n",
      "Unanswered question 131 will receive score 0.\n",
      "Unanswered question 132 will receive score 0.\n",
      "Unanswered question 133 will receive score 0.\n",
      "Unanswered question 134 will receive score 0.\n",
      "Unanswered question 135 will receive score 0.\n",
      "Unanswered question 136 will receive score 0.\n",
      "Unanswered question 137 will receive score 0.\n",
      "Unanswered question 138 will receive score 0.\n",
      "Unanswered question 139 will receive score 0.\n",
      "Unanswered question 140 will receive score 0.\n",
      "Unanswered question 141 will receive score 0.\n",
      "Unanswered question 142 will receive score 0.\n",
      "Unanswered question 143 will receive score 0.\n",
      "Unanswered question 144 will receive score 0.\n",
      "Unanswered question 145 will receive score 0.\n",
      "Unanswered question 146 will receive score 0.\n",
      "Unanswered question 147 will receive score 0.\n",
      "Unanswered question 148 will receive score 0.\n",
      "Unanswered question 149 will receive score 0.\n",
      "Unanswered question 150 will receive score 0.\n",
      "Unanswered question 151 will receive score 0.\n",
      "Unanswered question 152 will receive score 0.\n",
      "Unanswered question 153 will receive score 0.\n",
      "Unanswered question 154 will receive score 0.\n",
      "Unanswered question 155 will receive score 0.\n",
      "Unanswered question 156 will receive score 0.\n",
      "Unanswered question 157 will receive score 0.\n",
      "Unanswered question 158 will receive score 0.\n",
      "Unanswered question 159 will receive score 0.\n",
      "Unanswered question 160 will receive score 0.\n",
      "Unanswered question 161 will receive score 0.\n",
      "Unanswered question 162 will receive score 0.\n",
      "Unanswered question 163 will receive score 0.\n",
      "Unanswered question 164 will receive score 0.\n",
      "Unanswered question 165 will receive score 0.\n",
      "Unanswered question 166 will receive score 0.\n",
      "Unanswered question 167 will receive score 0.\n",
      "Unanswered question 168 will receive score 0.\n",
      "Unanswered question 169 will receive score 0.\n",
      "Unanswered question 170 will receive score 0.\n",
      "Unanswered question 171 will receive score 0.\n",
      "Unanswered question 172 will receive score 0.\n",
      "Unanswered question 173 will receive score 0.\n",
      "Unanswered question 174 will receive score 0.\n",
      "Unanswered question 175 will receive score 0.\n",
      "Unanswered question 176 will receive score 0.\n",
      "Unanswered question 177 will receive score 0.\n",
      "Unanswered question 178 will receive score 0.\n",
      "Unanswered question 179 will receive score 0.\n",
      "Unanswered question 180 will receive score 0.\n",
      "Unanswered question 181 will receive score 0.\n",
      "Unanswered question 182 will receive score 0.\n",
      "Unanswered question 183 will receive score 0.\n",
      "Unanswered question 184 will receive score 0.\n",
      "Unanswered question 185 will receive score 0.\n",
      "Unanswered question 186 will receive score 0.\n",
      "Unanswered question 187 will receive score 0.\n",
      "Unanswered question 188 will receive score 0.\n",
      "Unanswered question 189 will receive score 0.\n",
      "Unanswered question 190 will receive score 0.\n",
      "Unanswered question 191 will receive score 0.\n",
      "Unanswered question 192 will receive score 0.\n",
      "Unanswered question 193 will receive score 0.\n",
      "Unanswered question 194 will receive score 0.\n",
      "Unanswered question 195 will receive score 0.\n",
      "Unanswered question 196 will receive score 0.\n",
      "Unanswered question 197 will receive score 0.\n",
      "Unanswered question 198 will receive score 0.\n",
      "Unanswered question 199 will receive score 0.\n",
      "Unanswered question 200 will receive score 0.\n",
      "Unanswered question 201 will receive score 0.\n",
      "Unanswered question 202 will receive score 0.\n",
      "Unanswered question 203 will receive score 0.\n",
      "Unanswered question 204 will receive score 0.\n",
      "Unanswered question 205 will receive score 0.\n",
      "Unanswered question 206 will receive score 0.\n",
      "Unanswered question 207 will receive score 0.\n",
      "Unanswered question 208 will receive score 0.\n",
      "Unanswered question 209 will receive score 0.\n",
      "Unanswered question 210 will receive score 0.\n",
      "Unanswered question 211 will receive score 0.\n",
      "Unanswered question 212 will receive score 0.\n",
      "Unanswered question 213 will receive score 0.\n",
      "Unanswered question 214 will receive score 0.\n",
      "Unanswered question 215 will receive score 0.\n",
      "Unanswered question 216 will receive score 0.\n",
      "Unanswered question 217 will receive score 0.\n",
      "Unanswered question 218 will receive score 0.\n",
      "Unanswered question 219 will receive score 0.\n",
      "Unanswered question 220 will receive score 0.\n",
      "Unanswered question 221 will receive score 0.\n",
      "Unanswered question 222 will receive score 0.\n",
      "Unanswered question 223 will receive score 0.\n",
      "Unanswered question 224 will receive score 0.\n",
      "Unanswered question 225 will receive score 0.\n",
      "Unanswered question 226 will receive score 0.\n",
      "Unanswered question 227 will receive score 0.\n",
      "Unanswered question 228 will receive score 0.\n",
      "Unanswered question 229 will receive score 0.\n",
      "Unanswered question 230 will receive score 0.\n",
      "Unanswered question 231 will receive score 0.\n",
      "Unanswered question 232 will receive score 0.\n",
      "Unanswered question 233 will receive score 0.\n",
      "Unanswered question 234 will receive score 0.\n",
      "Unanswered question 235 will receive score 0.\n",
      "Unanswered question 236 will receive score 0.\n",
      "Unanswered question 237 will receive score 0.\n",
      "Unanswered question 238 will receive score 0.\n",
      "Unanswered question 239 will receive score 0.\n",
      "Unanswered question 240 will receive score 0.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "# load ground truth data\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json', 'r') as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "# load predicted data\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json', 'r') as f:\n",
    "    predicted = json.load(f)\n",
    "\n",
    "# save predicted data in SQuAD format\n",
    "data = []\n",
    "for article in predicted['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        qas = []\n",
    "        for qa in paragraph['qas']:\n",
    "            qas_id = qa['id']\n",
    "            question = qa['question']\n",
    "            answers = [{'text': answer['text'], 'answer_start': answer['answer_start']} for answer in qa['answers']]\n",
    "            qas.append({'id': qas_id, 'question': question, 'answers': answers})\n",
    "        data.append({'paragraphs': [{'context': context, 'qas': qas}]})\n",
    "\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json', 'w') as f:\n",
    "    json.dump({'version': '1.1', 'data': data}, f)\n",
    "\n",
    "# evaluate\n",
    "cmd = ['python', 'evaluate-v1.1.py', '/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json', '/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json']\n",
    "result = subprocess.run(cmd, stdout=subprocess.PIPE)\n",
    "\n",
    "print(result.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing id 1 in predicted data\n",
      "Missing id 2 in predicted data\n",
      "Missing id 3 in predicted data\n",
      "Missing id 4 in predicted data\n",
      "Missing id 5 in predicted data\n",
      "Missing id 6 in predicted data\n",
      "Missing id 7 in predicted data\n",
      "Missing id 8 in predicted data\n",
      "Missing id 9 in predicted data\n",
      "Missing id 10 in predicted data\n",
      "Missing id 11 in predicted data\n",
      "Missing id 12 in predicted data\n",
      "Missing id 13 in predicted data\n",
      "Missing id 14 in predicted data\n",
      "Missing id 15 in predicted data\n",
      "Missing id 16 in predicted data\n",
      "Missing id 17 in predicted data\n",
      "Missing id 18 in predicted data\n",
      "Missing id 19 in predicted data\n",
      "Missing id 20 in predicted data\n",
      "Missing id 21 in predicted data\n",
      "Missing id 22 in predicted data\n",
      "Missing id 23 in predicted data\n",
      "Missing id 24 in predicted data\n",
      "Missing id 25 in predicted data\n",
      "Missing id 26 in predicted data\n",
      "Missing id 27 in predicted data\n",
      "Missing id 28 in predicted data\n",
      "Missing id 29 in predicted data\n",
      "Missing id 30 in predicted data\n",
      "Missing id 31 in predicted data\n",
      "Missing id 32 in predicted data\n",
      "Missing id 33 in predicted data\n",
      "Missing id 34 in predicted data\n",
      "Missing id 35 in predicted data\n",
      "Missing id 36 in predicted data\n",
      "Missing id 37 in predicted data\n",
      "Missing id 38 in predicted data\n",
      "Missing id 39 in predicted data\n",
      "Missing id 40 in predicted data\n",
      "Missing id 41 in predicted data\n",
      "Missing id 42 in predicted data\n",
      "Missing id 43 in predicted data\n",
      "Missing id 44 in predicted data\n",
      "Missing id 45 in predicted data\n",
      "Missing id 46 in predicted data\n",
      "Missing id 47 in predicted data\n",
      "Missing id 48 in predicted data\n",
      "Missing id 49 in predicted data\n",
      "Missing id 50 in predicted data\n",
      "Missing id 51 in predicted data\n",
      "Missing id 52 in predicted data\n",
      "Missing id 53 in predicted data\n",
      "Missing id 54 in predicted data\n",
      "Missing id 55 in predicted data\n",
      "Missing id 56 in predicted data\n",
      "Missing id 57 in predicted data\n",
      "Missing id 58 in predicted data\n",
      "Missing id 59 in predicted data\n",
      "Missing id 60 in predicted data\n",
      "Missing id 61 in predicted data\n",
      "Missing id 62 in predicted data\n",
      "Missing id 63 in predicted data\n",
      "Missing id 64 in predicted data\n",
      "Missing id 65 in predicted data\n",
      "Missing id 66 in predicted data\n",
      "Missing id 67 in predicted data\n",
      "Missing id 68 in predicted data\n",
      "Missing id 69 in predicted data\n",
      "Missing id 70 in predicted data\n",
      "Missing id 71 in predicted data\n",
      "Missing id 72 in predicted data\n",
      "Missing id 73 in predicted data\n",
      "Missing id 74 in predicted data\n",
      "Missing id 75 in predicted data\n",
      "Missing id 76 in predicted data\n",
      "Missing id 77 in predicted data\n",
      "Missing id 78 in predicted data\n",
      "Missing id 79 in predicted data\n",
      "Missing id 80 in predicted data\n",
      "Missing id 81 in predicted data\n",
      "Missing id 82 in predicted data\n",
      "Missing id 83 in predicted data\n",
      "Missing id 84 in predicted data\n",
      "Missing id 85 in predicted data\n",
      "Missing id 86 in predicted data\n",
      "Missing id 87 in predicted data\n",
      "Missing id 88 in predicted data\n",
      "Missing id 89 in predicted data\n",
      "Missing id 90 in predicted data\n",
      "Missing id 91 in predicted data\n",
      "Missing id 92 in predicted data\n",
      "Missing id 93 in predicted data\n",
      "Missing id 94 in predicted data\n",
      "Missing id 95 in predicted data\n",
      "Missing id 96 in predicted data\n",
      "Missing id 97 in predicted data\n",
      "Missing id 98 in predicted data\n",
      "Missing id 99 in predicted data\n",
      "Missing id 100 in predicted data\n",
      "Missing id 101 in predicted data\n",
      "Missing id 102 in predicted data\n",
      "Missing id 103 in predicted data\n",
      "Missing id 104 in predicted data\n",
      "Missing id 105 in predicted data\n",
      "Missing id 106 in predicted data\n",
      "Missing id 107 in predicted data\n",
      "Missing id 108 in predicted data\n",
      "Missing id 109 in predicted data\n",
      "Missing id 110 in predicted data\n",
      "Missing id 111 in predicted data\n",
      "Missing id 112 in predicted data\n",
      "Missing id 113 in predicted data\n",
      "Missing id 114 in predicted data\n",
      "Missing id 115 in predicted data\n",
      "Missing id 116 in predicted data\n",
      "Missing id 117 in predicted data\n",
      "Missing id 118 in predicted data\n",
      "Missing id 119 in predicted data\n",
      "Missing id 120 in predicted data\n",
      "Missing id 121 in predicted data\n",
      "Missing id 122 in predicted data\n",
      "Missing id 123 in predicted data\n",
      "Missing id 124 in predicted data\n",
      "Missing id 125 in predicted data\n",
      "Missing id 126 in predicted data\n",
      "Missing id 127 in predicted data\n",
      "Missing id 128 in predicted data\n",
      "Missing id 129 in predicted data\n",
      "Missing id 130 in predicted data\n",
      "Missing id 131 in predicted data\n",
      "Missing id 132 in predicted data\n",
      "Missing id 133 in predicted data\n",
      "Missing id 134 in predicted data\n",
      "Missing id 135 in predicted data\n",
      "Missing id 136 in predicted data\n",
      "Missing id 137 in predicted data\n",
      "Missing id 138 in predicted data\n",
      "Missing id 139 in predicted data\n",
      "Missing id 140 in predicted data\n",
      "Missing id 141 in predicted data\n",
      "Missing id 142 in predicted data\n",
      "Missing id 143 in predicted data\n",
      "Missing id 144 in predicted data\n",
      "Missing id 145 in predicted data\n",
      "Missing id 146 in predicted data\n",
      "Missing id 147 in predicted data\n",
      "Missing id 148 in predicted data\n",
      "Missing id 149 in predicted data\n",
      "Missing id 150 in predicted data\n",
      "Missing id 151 in predicted data\n",
      "Missing id 152 in predicted data\n",
      "Missing id 153 in predicted data\n",
      "Missing id 154 in predicted data\n",
      "Missing id 155 in predicted data\n",
      "Missing id 156 in predicted data\n",
      "Missing id 157 in predicted data\n",
      "Missing id 158 in predicted data\n",
      "Missing id 159 in predicted data\n",
      "Missing id 160 in predicted data\n",
      "Missing id 161 in predicted data\n",
      "Missing id 162 in predicted data\n",
      "Missing id 163 in predicted data\n",
      "Missing id 164 in predicted data\n",
      "Missing id 165 in predicted data\n",
      "Missing id 166 in predicted data\n",
      "Missing id 167 in predicted data\n",
      "Missing id 168 in predicted data\n",
      "Missing id 169 in predicted data\n",
      "Missing id 170 in predicted data\n",
      "Missing id 171 in predicted data\n",
      "Missing id 172 in predicted data\n",
      "Missing id 173 in predicted data\n",
      "Missing id 174 in predicted data\n",
      "Missing id 175 in predicted data\n",
      "Missing id 176 in predicted data\n",
      "Missing id 177 in predicted data\n",
      "Missing id 178 in predicted data\n",
      "Missing id 179 in predicted data\n",
      "Missing id 180 in predicted data\n",
      "Missing id 181 in predicted data\n",
      "Missing id 182 in predicted data\n",
      "Missing id 183 in predicted data\n",
      "Missing id 184 in predicted data\n",
      "Missing id 185 in predicted data\n",
      "Missing id 186 in predicted data\n",
      "Missing id 187 in predicted data\n",
      "Missing id 188 in predicted data\n",
      "Missing id 189 in predicted data\n",
      "Missing id 190 in predicted data\n",
      "Missing id 191 in predicted data\n",
      "Missing id 192 in predicted data\n",
      "Missing id 193 in predicted data\n",
      "Missing id 194 in predicted data\n",
      "Missing id 195 in predicted data\n",
      "Missing id 196 in predicted data\n",
      "Missing id 197 in predicted data\n",
      "Missing id 198 in predicted data\n",
      "Missing id 199 in predicted data\n",
      "Missing id 200 in predicted data\n",
      "Missing id 201 in predicted data\n",
      "Missing id 202 in predicted data\n",
      "Missing id 203 in predicted data\n",
      "Missing id 204 in predicted data\n",
      "Missing id 205 in predicted data\n",
      "Missing id 206 in predicted data\n",
      "Missing id 207 in predicted data\n",
      "Missing id 208 in predicted data\n",
      "Missing id 209 in predicted data\n",
      "Missing id 210 in predicted data\n",
      "Missing id 211 in predicted data\n",
      "Missing id 212 in predicted data\n",
      "Missing id 213 in predicted data\n",
      "Missing id 214 in predicted data\n",
      "Missing id 215 in predicted data\n",
      "Missing id 216 in predicted data\n",
      "Missing id 217 in predicted data\n",
      "Missing id 218 in predicted data\n",
      "Missing id 219 in predicted data\n",
      "Missing id 220 in predicted data\n",
      "Missing id 221 in predicted data\n",
      "Missing id 222 in predicted data\n",
      "Missing id 223 in predicted data\n",
      "Missing id 224 in predicted data\n",
      "Missing id 225 in predicted data\n",
      "Missing id 226 in predicted data\n",
      "Missing id 227 in predicted data\n",
      "Missing id 228 in predicted data\n",
      "Missing id 229 in predicted data\n",
      "Missing id 230 in predicted data\n",
      "Missing id 231 in predicted data\n",
      "Missing id 232 in predicted data\n",
      "Missing id 233 in predicted data\n",
      "Missing id 234 in predicted data\n",
      "Missing id 235 in predicted data\n",
      "Missing id 236 in predicted data\n",
      "Missing id 237 in predicted data\n",
      "Missing id 238 in predicted data\n",
      "Missing id 239 in predicted data\n",
      "Missing id 240 in predicted data\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "IDs in ground truth: {'61', '103', '157', '130', '167', '135', '201', '78', '98', '86', '28', '4', '25', '69', '205', '236', '118', '151', '62', '173', '213', '72', '156', '150', '210', '39', '215', '158', '217', '52', '104', '172', '203', '49', '58', '17', '65', '178', '186', '222', '175', '162', '142', '148', '102', '64', '193', '110', '228', '211', '223', '63', '24', '45', '204', '187', '82', '109', '141', '60', '120', '149', '234', '119', '5', '37', '56', '108', '97', '53', '14', '212', '206', '221', '10', '89', '115', '231', '200', '100', '180', '59', '48', '55', '129', '166', '107', '174', '227', '126', '139', '161', '70', '138', '127', '179', '116', '85', '209', '23', '188', '177', '182', '26', '43', '114', '128', '159', '170', '21', '80', '226', '185', '76', '155', '111', '94', '184', '67', '96', '34', '3', '191', '237', '7', '92', '154', '50', '121', '163', '216', '131', '29', '51', '15', '20', '123', '57', '77', '87', '122', '133', '140', '224', '38', '47', '73', '83', '195', '19', '196', '233', '2', '176', '81', '125', '181', '9', '6', '136', '202', '1', '32', '124', '46', '183', '235', '66', '208', '27', '79', '144', '22', '117', '132', '229', '153', '220', '36', '165', '90', '160', '197', '143', '68', '18', '44', '145', '40', '199', '238', '30', '84', '112', '54', '16', '88', '106', '101', '113', '31', '93', '137', '71', '95', '189', '230', '169', '164', '91', '240', '35', '239', '99', '8', '198', '214', '41', '13', '232', '147', '219', '74', '75', '225', '168', '33', '12', '152', '190', '11', '146', '134', '218', '171', '192', '194', '42', '105', '207'}\n",
      "IDs in predicted: {'version', 'data'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Load ground truth data\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json', 'r') as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "# Load predicted data\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json', 'r') as f:\n",
    "    predicted = json.load(f)\n",
    "\n",
    "# Flatten ground truth and predicted data\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for article in ground_truth['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            qa_id = qa['id']\n",
    "            if qa_id not in predicted:\n",
    "                print(f\"Missing id {qa_id} in predicted data\")\n",
    "            else:\n",
    "                y_true.append(qa['answers'][0]['text'])  # Assume only one answer per question\n",
    "                y_pred.append(predicted[qa_id][0])  # Assume only one answer per question\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1_score)\n",
    "\n",
    "# Print out the IDs in the ground truth and predicted data\n",
    "gt_ids = set()\n",
    "pred_ids = set()\n",
    "for article in ground_truth['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            qa_id = qa['id']\n",
    "            gt_ids.add(qa_id)\n",
    "for qa_id in predicted:\n",
    "    pred_ids.add(qa_id)\n",
    "print(f\"IDs in ground truth: {gt_ids}\")\n",
    "print(f\"IDs in predicted: {pred_ids}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the ground-truth and predicted files\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json') as f:\n",
    "    gt = json.load(f)\n",
    "    \n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json') as f:\n",
    "    pred = json.load(f)\n",
    "\n",
    "# Extract the question ids from the ground-truth file\n",
    "gt_ids = []\n",
    "for article in gt['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            gt_ids.append(qa['id'])\n",
    "\n",
    "# Extract the question ids from the predicted file\n",
    "pred_ids = []\n",
    "for article in pred['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            pred_ids.append(qa['id'])\n",
    "\n",
    "# Check if the ids are consistent between the ground-truth and predicted files\n",
    "print(set(gt_ids) == set(pred_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing id 1 in predicted data\n",
      "Missing id 2 in predicted data\n",
      "Missing id 3 in predicted data\n",
      "Missing id 4 in predicted data\n",
      "Missing id 5 in predicted data\n",
      "Missing id 6 in predicted data\n",
      "Missing id 7 in predicted data\n",
      "Missing id 8 in predicted data\n",
      "Missing id 9 in predicted data\n",
      "Missing id 10 in predicted data\n",
      "Missing id 11 in predicted data\n",
      "Missing id 12 in predicted data\n",
      "Missing id 13 in predicted data\n",
      "Missing id 14 in predicted data\n",
      "Missing id 15 in predicted data\n",
      "Missing id 16 in predicted data\n",
      "Missing id 17 in predicted data\n",
      "Missing id 18 in predicted data\n",
      "Missing id 19 in predicted data\n",
      "Missing id 20 in predicted data\n",
      "Missing id 21 in predicted data\n",
      "Missing id 22 in predicted data\n",
      "Missing id 23 in predicted data\n",
      "Missing id 24 in predicted data\n",
      "Missing id 25 in predicted data\n",
      "Missing id 26 in predicted data\n",
      "Missing id 27 in predicted data\n",
      "Missing id 28 in predicted data\n",
      "Missing id 29 in predicted data\n",
      "Missing id 30 in predicted data\n",
      "Missing id 31 in predicted data\n",
      "Missing id 32 in predicted data\n",
      "Missing id 33 in predicted data\n",
      "Missing id 34 in predicted data\n",
      "Missing id 35 in predicted data\n",
      "Missing id 36 in predicted data\n",
      "Missing id 37 in predicted data\n",
      "Missing id 38 in predicted data\n",
      "Missing id 39 in predicted data\n",
      "Missing id 40 in predicted data\n",
      "Missing id 41 in predicted data\n",
      "Missing id 42 in predicted data\n",
      "Missing id 43 in predicted data\n",
      "Missing id 44 in predicted data\n",
      "Missing id 45 in predicted data\n",
      "Missing id 46 in predicted data\n",
      "Missing id 47 in predicted data\n",
      "Missing id 48 in predicted data\n",
      "Missing id 49 in predicted data\n",
      "Missing id 50 in predicted data\n",
      "Missing id 51 in predicted data\n",
      "Missing id 52 in predicted data\n",
      "Missing id 53 in predicted data\n",
      "Missing id 54 in predicted data\n",
      "Missing id 55 in predicted data\n",
      "Missing id 56 in predicted data\n",
      "Missing id 57 in predicted data\n",
      "Missing id 58 in predicted data\n",
      "Missing id 59 in predicted data\n",
      "Missing id 60 in predicted data\n",
      "Missing id 61 in predicted data\n",
      "Missing id 62 in predicted data\n",
      "Missing id 63 in predicted data\n",
      "Missing id 64 in predicted data\n",
      "Missing id 65 in predicted data\n",
      "Missing id 66 in predicted data\n",
      "Missing id 67 in predicted data\n",
      "Missing id 68 in predicted data\n",
      "Missing id 69 in predicted data\n",
      "Missing id 70 in predicted data\n",
      "Missing id 71 in predicted data\n",
      "Missing id 72 in predicted data\n",
      "Missing id 73 in predicted data\n",
      "Missing id 74 in predicted data\n",
      "Missing id 75 in predicted data\n",
      "Missing id 76 in predicted data\n",
      "Missing id 77 in predicted data\n",
      "Missing id 78 in predicted data\n",
      "Missing id 79 in predicted data\n",
      "Missing id 80 in predicted data\n",
      "Missing id 81 in predicted data\n",
      "Missing id 82 in predicted data\n",
      "Missing id 83 in predicted data\n",
      "Missing id 84 in predicted data\n",
      "Missing id 85 in predicted data\n",
      "Missing id 86 in predicted data\n",
      "Missing id 87 in predicted data\n",
      "Missing id 88 in predicted data\n",
      "Missing id 89 in predicted data\n",
      "Missing id 90 in predicted data\n",
      "Missing id 91 in predicted data\n",
      "Missing id 92 in predicted data\n",
      "Missing id 93 in predicted data\n",
      "Missing id 94 in predicted data\n",
      "Missing id 95 in predicted data\n",
      "Missing id 96 in predicted data\n",
      "Missing id 97 in predicted data\n",
      "Missing id 98 in predicted data\n",
      "Missing id 99 in predicted data\n",
      "Missing id 100 in predicted data\n",
      "Missing id 101 in predicted data\n",
      "Missing id 102 in predicted data\n",
      "Missing id 103 in predicted data\n",
      "Missing id 104 in predicted data\n",
      "Missing id 105 in predicted data\n",
      "Missing id 106 in predicted data\n",
      "Missing id 107 in predicted data\n",
      "Missing id 108 in predicted data\n",
      "Missing id 109 in predicted data\n",
      "Missing id 110 in predicted data\n",
      "Missing id 111 in predicted data\n",
      "Missing id 112 in predicted data\n",
      "Missing id 113 in predicted data\n",
      "Missing id 114 in predicted data\n",
      "Missing id 115 in predicted data\n",
      "Missing id 116 in predicted data\n",
      "Missing id 117 in predicted data\n",
      "Missing id 118 in predicted data\n",
      "Missing id 119 in predicted data\n",
      "Missing id 120 in predicted data\n",
      "Missing id 121 in predicted data\n",
      "Missing id 122 in predicted data\n",
      "Missing id 123 in predicted data\n",
      "Missing id 124 in predicted data\n",
      "Missing id 125 in predicted data\n",
      "Missing id 126 in predicted data\n",
      "Missing id 127 in predicted data\n",
      "Missing id 128 in predicted data\n",
      "Missing id 129 in predicted data\n",
      "Missing id 130 in predicted data\n",
      "Missing id 131 in predicted data\n",
      "Missing id 132 in predicted data\n",
      "Missing id 133 in predicted data\n",
      "Missing id 134 in predicted data\n",
      "Missing id 135 in predicted data\n",
      "Missing id 136 in predicted data\n",
      "Missing id 137 in predicted data\n",
      "Missing id 138 in predicted data\n",
      "Missing id 139 in predicted data\n",
      "Missing id 140 in predicted data\n",
      "Missing id 141 in predicted data\n",
      "Missing id 142 in predicted data\n",
      "Missing id 143 in predicted data\n",
      "Missing id 144 in predicted data\n",
      "Missing id 145 in predicted data\n",
      "Missing id 146 in predicted data\n",
      "Missing id 147 in predicted data\n",
      "Missing id 148 in predicted data\n",
      "Missing id 149 in predicted data\n",
      "Missing id 150 in predicted data\n",
      "Missing id 151 in predicted data\n",
      "Missing id 152 in predicted data\n",
      "Missing id 153 in predicted data\n",
      "Missing id 154 in predicted data\n",
      "Missing id 155 in predicted data\n",
      "Missing id 156 in predicted data\n",
      "Missing id 157 in predicted data\n",
      "Missing id 158 in predicted data\n",
      "Missing id 159 in predicted data\n",
      "Missing id 160 in predicted data\n",
      "Missing id 161 in predicted data\n",
      "Missing id 162 in predicted data\n",
      "Missing id 163 in predicted data\n",
      "Missing id 164 in predicted data\n",
      "Missing id 165 in predicted data\n",
      "Missing id 166 in predicted data\n",
      "Missing id 167 in predicted data\n",
      "Missing id 168 in predicted data\n",
      "Missing id 169 in predicted data\n",
      "Missing id 170 in predicted data\n",
      "Missing id 171 in predicted data\n",
      "Missing id 172 in predicted data\n",
      "Missing id 173 in predicted data\n",
      "Missing id 174 in predicted data\n",
      "Missing id 175 in predicted data\n",
      "Missing id 176 in predicted data\n",
      "Missing id 177 in predicted data\n",
      "Missing id 178 in predicted data\n",
      "Missing id 179 in predicted data\n",
      "Missing id 180 in predicted data\n",
      "Missing id 181 in predicted data\n",
      "Missing id 182 in predicted data\n",
      "Missing id 183 in predicted data\n",
      "Missing id 184 in predicted data\n",
      "Missing id 185 in predicted data\n",
      "Missing id 186 in predicted data\n",
      "Missing id 187 in predicted data\n",
      "Missing id 188 in predicted data\n",
      "Missing id 189 in predicted data\n",
      "Missing id 190 in predicted data\n",
      "Missing id 191 in predicted data\n",
      "Missing id 192 in predicted data\n",
      "Missing id 193 in predicted data\n",
      "Missing id 194 in predicted data\n",
      "Missing id 195 in predicted data\n",
      "Missing id 196 in predicted data\n",
      "Missing id 197 in predicted data\n",
      "Missing id 198 in predicted data\n",
      "Missing id 199 in predicted data\n",
      "Missing id 200 in predicted data\n",
      "Missing id 201 in predicted data\n",
      "Missing id 202 in predicted data\n",
      "Missing id 203 in predicted data\n",
      "Missing id 204 in predicted data\n",
      "Missing id 205 in predicted data\n",
      "Missing id 206 in predicted data\n",
      "Missing id 207 in predicted data\n",
      "Missing id 208 in predicted data\n",
      "Missing id 209 in predicted data\n",
      "Missing id 210 in predicted data\n",
      "Missing id 211 in predicted data\n",
      "Missing id 212 in predicted data\n",
      "Missing id 213 in predicted data\n",
      "Missing id 214 in predicted data\n",
      "Missing id 215 in predicted data\n",
      "Missing id 216 in predicted data\n",
      "Missing id 217 in predicted data\n",
      "Missing id 218 in predicted data\n",
      "Missing id 219 in predicted data\n",
      "Missing id 220 in predicted data\n",
      "Missing id 221 in predicted data\n",
      "Missing id 222 in predicted data\n",
      "Missing id 223 in predicted data\n",
      "Missing id 224 in predicted data\n",
      "Missing id 225 in predicted data\n",
      "Missing id 226 in predicted data\n",
      "Missing id 227 in predicted data\n",
      "Missing id 228 in predicted data\n",
      "Missing id 229 in predicted data\n",
      "Missing id 230 in predicted data\n",
      "Missing id 231 in predicted data\n",
      "Missing id 232 in predicted data\n",
      "Missing id 233 in predicted data\n",
      "Missing id 234 in predicted data\n",
      "Missing id 235 in predicted data\n",
      "Missing id 236 in predicted data\n",
      "Missing id 237 in predicted data\n",
      "Missing id 238 in predicted data\n",
      "Missing id 239 in predicted data\n",
      "Missing id 240 in predicted data\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Load ground truth data\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json', 'r') as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "# Load predicted data\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_squad_finetune_qa_generated_results.json', 'r') as f:\n",
    "    predicted = json.load(f)\n",
    "\n",
    "# Flatten ground truth and predicted data\n",
    "y_true = []\n",
    "y_pred = []\n",
    "confidence_scores = []\n",
    "for article in ground_truth['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            qa_id = qa['id']\n",
    "            if qa_id not in predicted:\n",
    "                print(f\"Missing id {qa_id} in predicted data\")\n",
    "            else:\n",
    "                y_true.append(qa['answers'][0]['text'])  # Assume only one answer per question\n",
    "                pred_answer = predicted[qa_id][0]['text']  # Assume only one answer per question\n",
    "                confidence_scores.append(predicted[qa_id][0]['score'])  # Get confidence score for the predicted answer\n",
    "                if pred_answer == \"\":\n",
    "                    y_pred.append(\"No Answer\")  # Treat empty answer as incorrect\n",
    "                else:\n",
    "                    y_pred.append(pred_answer)\n",
    "\n",
    "# Set a threshold for confidence scores\n",
    "threshold = 0.5\n",
    "\n",
    "# Classify predicted answers as correct or incorrect based on the threshold\n",
    "y_pred_binary = [1 if score >= threshold else 0 for score in confidence_scores]\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.28k/5.28k [00:00<00:00, 3.97MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.40k/2.40k [00:00<00:00, 2.03MB/s]\n",
      "Downloading readme: 100%|██████████| 8.02k/8.02k [00:00<00:00, 5.76MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad_v2/squad_v2 to /home/ssarrouf/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 42.1MB [00:00, 96.3MB/s]/2 [00:00<?, ?it/s]\n",
      "Downloading data: 4.37MB [00:00, 55.9MB/s]                  1.51s/it]\n",
      "Downloading data files: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 1119.82it/s]\n",
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad_v2 downloaded and prepared to /home/ssarrouf/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 359.62it/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 7.75kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 483/483 [00:00<00:00, 153kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.90MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 5.84MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 268M/268M [00:03<00:00, 79.7MB/s] \n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ssarrouf/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/tmp/ipykernel_1890194/2341894424.py:32: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad_v2\")\n",
      "Downloading builder script: 6.46kB [00:00, 4.55MB/s]                   \n",
      "Downloading extra modules: 11.3kB [00:00, 7.29MB/s]                   \n",
      "                                                      \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mstart_positions\u001b[39m\u001b[39m\"\u001b[39m: targets[\u001b[39m\"\u001b[39m\u001b[39mstart_positions\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mend_positions\u001b[39m\u001b[39m\"\u001b[39m: targets[\u001b[39m\"\u001b[39m\u001b[39mend_positions\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m     45\u001b[0m \u001b[39m# Preprocess the dataset\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(preprocess_function, batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     48\u001b[0m \u001b[39m# Define the function to compute the metrics during training\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_metrics\u001b[39m(eval_preds):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/dataset_dict.py:852\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    851\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 852\u001b[0m     {\n\u001b[1;32m    853\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[1;32m    854\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[1;32m    855\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[1;32m    856\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[1;32m    857\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[1;32m    858\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[1;32m    859\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    860\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    861\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[1;32m    862\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    863\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    864\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    865\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    866\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m    867\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[1;32m    868\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[1;32m    869\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[1;32m    870\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[1;32m    871\u001b[0m         )\n\u001b[1;32m    872\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    873\u001b[0m     }\n\u001b[1;32m    874\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/dataset_dict.py:853\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[1;32m    851\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    852\u001b[0m     {\n\u001b[0;32m--> 853\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m    854\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m    855\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m    856\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m    857\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m    858\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m    859\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    860\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m    861\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m    862\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m    863\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m    864\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[1;32m    865\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m    866\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m    867\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m    868\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m    869\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m    870\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m    871\u001b[0m         )\n\u001b[1;32m    872\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    873\u001b[0m     }\n\u001b[1;32m    874\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    526\u001b[0m }\n\u001b[1;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:2953\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2945\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2946\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   2947\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   2948\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2952\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 2953\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   2954\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   2955\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:3329\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3325\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   3326\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   3327\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3328\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3329\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   3330\u001b[0m         batch,\n\u001b[1;32m   3331\u001b[0m         indices,\n\u001b[1;32m   3332\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   3333\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   3334\u001b[0m     )\n\u001b[1;32m   3335\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3336\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3338\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/arrow_dataset.py:3210\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3208\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3209\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3210\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3212\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3213\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3214\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_function\u001b[39m(examples):\n\u001b[1;32m     36\u001b[0m     \u001b[39m# Tokenize the inputs and targets\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     inputs \u001b[39m=\u001b[39m tokenizer(examples[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m], examples[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m], truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m     targets \u001b[39m=\u001b[39m {\n\u001b[0;32m---> 39\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstart_positions\u001b[39m\u001b[39m\"\u001b[39m: examples[\u001b[39m\"\u001b[39;49m\u001b[39manswers\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39manswer_start\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     40\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mend_positions\u001b[39m\u001b[39m\"\u001b[39m: examples[\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39manswer_start\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(examples[\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     41\u001b[0m     }\n\u001b[1;32m     42\u001b[0m     \u001b[39m# Return the preprocessed examples\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mstart_positions\u001b[39m\u001b[39m\"\u001b[39m: targets[\u001b[39m\"\u001b[39m\u001b[39mstart_positions\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mend_positions\u001b[39m\u001b[39m\"\u001b[39m: targets[\u001b[39m\"\u001b[39m\u001b[39mend_positions\u001b[39m\u001b[39m\"\u001b[39m]}\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "# Load the SQuAD v2.0 dataset\n",
    "dataset = load_dataset(\"squad_v2\")\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           # Output directory\n",
    "    evaluation_strategy=\"steps\",      # Evaluation strategy to adopt during training\n",
    "    eval_steps=500,                   # Evaluation and Save happens every eval_steps\n",
    "    save_total_limit=2,               # Only last 2 models are saved. Older ones are deleted.\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1000,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# Define the metric to use for evaluation\n",
    "metric = load_metric(\"squad_v2\")\n",
    "\n",
    "# Define the function to preprocess the dataset\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the inputs and targets\n",
    "    inputs = tokenizer(examples[\"question\"], examples[\"context\"], truncation=True)\n",
    "    targets = {\n",
    "        \"start_positions\": examples[\"answers\"][\"answer_start\"],\n",
    "        \"end_positions\": examples[\"answers\"][\"answer_start\"] + len(examples[\"answers\"][\"text\"]) - 1,\n",
    "    }\n",
    "    # Return the preprocessed examples\n",
    "    return {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"], \"start_positions\": targets[\"start_positions\"], \"end_positions\": targets[\"end_positions\"]}\n",
    "\n",
    "# Preprocess the dataset\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Define the function to compute the metrics during training\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Instantiate the Trainer class and train the model\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=dataset[\"train\"], eval_dataset=dataset[\"validation\"], compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example question: In what country is Normandy located?\n",
      "example context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
      "[101, 1999, 2054, 2406, 2003, 13298, 2284, 1029, 102, 1996, 5879, 2015, 1006, 5879, 1024, 2053, 3126, 2386, 5104, 1025, 2413, 1024, 5879, 5104, 1025, 3763, 1024, 5879, 3490, 1007, 2020, 1996, 2111, 2040, 1999, 1996, 6049, 1998, 6252, 4693, 2435, 2037, 2171, 2000, 13298, 1010, 1037, 2555, 1999, 2605, 1012, 2027, 2020, 9287, 2013, 15342, 1006, 1000, 5879, 1000, 3310, 2013, 1000, 15342, 2386, 1000, 1007, 10642, 1998, 8350, 2013, 5842, 1010, 10399, 1998, 5120, 2040, 1010, 2104, 2037, 3003, 4897, 2080, 1010, 3530, 2000, 8415, 10768, 2389, 3723, 2000, 2332, 2798, 3523, 1997, 2225, 23151, 7405, 1012, 2083, 8213, 1997, 27574, 1998, 6809, 2007, 1996, 3128, 26165, 1998, 3142, 1011, 26522, 4509, 7080, 1010, 2037, 8481, 2052, 6360, 13590, 2007, 1996, 8594, 2075, 2937, 1011, 2241, 8578, 1997, 2225, 23151, 7405, 1012, 1996, 5664, 3451, 1998, 5636, 4767, 1997, 1996, 5879, 2015, 6003, 3322, 1999, 1996, 2034, 2431, 1997, 1996, 6049, 2301, 1010, 1998, 2009, 2506, 2000, 19852, 2058, 1996, 13034, 4693, 1012, 102]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'start_logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m question \u001b[39m=\u001b[39m qa[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     93\u001b[0m context \u001b[39m=\u001b[39m paragraph[\u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 94\u001b[0m predicted_answer \u001b[39m=\u001b[39m answer_question(question, context)\n\u001b[1;32m     95\u001b[0m \u001b[39mfor\u001b[39;00m answer \u001b[39min\u001b[39;00m qa[\u001b[39m'\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m predicted_answer\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m answer[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mlower():\n",
      "Cell \u001b[0;32mIn[25], line 63\u001b[0m, in \u001b[0;36manswer_question\u001b[0;34m(question, answer_text)\u001b[0m\n\u001b[1;32m     61\u001b[0m start_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(start_scores)\n\u001b[1;32m     62\u001b[0m \u001b[39mprint\u001b[39m(start_scores\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 63\u001b[0m start_scores_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(start_scores\u001b[39m.\u001b[39;49mastype(\u001b[39mfloat\u001b[39;49m))\n\u001b[1;32m     64\u001b[0m \u001b[39m#start_scores = torch.tensor(start_scores)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m#end_scores = torch.tensor(end_scores)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m end_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(end_scores)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'start_logits'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "class Example:\n",
    "    def __init__(self, question, context):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "\n",
    "\n",
    "# Load the fine-tuned model checkpoint\n",
    "model_path = \"/home/ssarrouf/Documents/qa_output/checkpoint-10000/\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# Load the SQuAD validation set\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationBERT/dev-v2.0.json', 'r') as f:\n",
    "    squad = json.load(f)\n",
    "\n",
    "def create_example(question, context):\n",
    "    return Example(question, context)\n",
    "\n",
    "\n",
    "def tokenize_example(example):\n",
    "    # Tokenize the inputs\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        example.question,\n",
    "        example.context,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        truncation_strategy='only_second',\n",
    "        max_length=512\n",
    "    )\n",
    "    # Get the input_ids and segment_ids\n",
    "    input_ids = inputs['input_ids']\n",
    "    segment_ids = inputs['token_type_ids']\n",
    "\n",
    "    print(input_ids)\n",
    "    print(segment_ids)\n",
    "    return input_ids, segment_ids\n",
    "\n",
    "\n",
    "def answer_question(question, answer_text):\n",
    "    # Create input example\n",
    "    example = create_example(question, answer_text)\n",
    "    print(\"example question:\", example.question)\n",
    "    print(\"example context:\", example.context)\n",
    "\n",
    "    # Tokenize the example\n",
    "    input_ids, segment_ids = tokenize_example(example)\n",
    "\n",
    "    # Get the start and end scores from the model\n",
    "    \n",
    "    start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "\n",
    "    # Convert start and end scores to tensors\n",
    "    start_scores = np.array(start_scores)\n",
    "    print(start_scores.shape)\n",
    "    start_scores_tensor = torch.tensor(start_scores.astype(float))\n",
    "    #start_scores = torch.tensor(start_scores)\n",
    "    #end_scores = torch.tensor(end_scores)\n",
    "    end_scores = np.array(end_scores)\n",
    "    end_scores_tensor = torch.tensor(end_scores.astype(float))\n",
    "\n",
    "    # Find the tokens with the highest `start` and `end` scores\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the string versions of the input tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "# Evaluate the model on the SQuAD validation set\n",
    "correct_answers = 0\n",
    "for article in squad['data']:\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            question = qa['question']\n",
    "            context = paragraph['context']\n",
    "            predicted_answer = answer_question(question, context)\n",
    "            for answer in qa['answers']:\n",
    "                if predicted_answer.lower() == answer['text'].lower():\n",
    "                    correct_answers += 1\n",
    "                    break\n",
    "\n",
    "total_questions = len(squad['data'])\n",
    "accuracy = correct_answers / total_questions\n",
    "\n",
    "print(f\"Model accuracy on SQuAD validation set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForQuestionAnswering:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([28996, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Initialize a new instance of the BERT model and load the state dict\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[39m=\u001b[39m BertForQuestionAnswering\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict)\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     13\u001b[0m \u001b[39m# Load the tokenizer\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForQuestionAnswering:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([28996, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "\n",
    "# Load the fine-tuned BERT model\n",
    "model_path = '/home/ssarrouf/Documents/qa_output/checkpoint-10000/pytorch_model.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Initialize a new instance of the BERT model and load the state dict\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the input text\n",
    "context = \"My favorite food is pizza. I could eat pizza all day, every day!\"\n",
    "question = \"What is my favorite food?\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "# Get the start and end logits for the answer span\n",
    "start_logits, end_logits = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "# Find the tokens with the highest start and end logits\n",
    "start_index = torch.argmax(start_logits)\n",
    "end_index = torch.argmax(end_logits)\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "answer = tokens[start_index:end_index+1]\n",
    "answer = tokenizer.convert_tokens_to_string(answer)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertForQuestionAnswering:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([28996, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# Initialize a new instance of the BERT model and load the state dict\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model \u001b[39m=\u001b[39m BertForQuestionAnswering\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict)\n\u001b[1;32m     15\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     17\u001b[0m \u001b[39m# Load the SQuAD dev-v2.0 dataset\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertForQuestionAnswering:\n\tsize mismatch for bert.embeddings.word_embeddings.weight: copying a param with shape torch.Size([28996, 768]) from checkpoint, the shape in current model is torch.Size([30522, 768])."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Load the fine-tuned model's state dict\n",
    "model_path = '/home/ssarrouf/Documents/qa_output/checkpoint-10000/pytorch_model.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Initialize a new instance of the BERT model and load the state dict\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Load the SQuAD dev-v2.0 dataset\n",
    "data_path = '/home/ssarrouf/Documents/GitHub/WaterRemediationBERT/dev-v2.0.json'\n",
    "with open(data_path, 'r') as f:\n",
    "    squad_dev = json.load(f)['data']\n",
    "\n",
    "# Tokenize the input and get the predicted answer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "predictions = []\n",
    "true_answers = []\n",
    "for article in tqdm(squad_dev):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            question = qa['question']\n",
    "            context = paragraph['context']\n",
    "            input_ids = tokenizer.encode(question, context)\n",
    "            start_scores, end_scores = model(torch.tensor([input_ids]))\n",
    "            start_index = torch.argmax(start_scores)\n",
    "            end_index = torch.argmax(end_scores)\n",
    "            predicted_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[start_index:end_index+1]))\n",
    "            predictions.append(predicted_answer)\n",
    "            true_answers.append(qa['answers'][0]['text'])\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "f1 = f1_score(true_answers, predictions, average='weighted')\n",
    "precision = precision_score(true_answers, predictions, average='weighted')\n",
    "recall = recall_score(true_answers, predictions, average='weighted')\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unrecognized parameter \"embeddings.position_ids\" in the pre-trained model\n",
      "Unrecognized parameter \"embeddings.word_embeddings.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"embeddings.position_embeddings.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"embeddings.token_type_embeddings.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"embeddings.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"embeddings.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.0.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.1.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.2.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.3.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.4.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.5.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.6.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.7.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.8.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.9.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.10.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.self.query.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.self.query.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.self.key.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.self.key.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.self.value.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.self.value.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.attention.output.LayerNorm.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.intermediate.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.intermediate.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.output.dense.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.output.dense.bias\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.output.LayerNorm.weight\" in the pre-trained model\n",
      "Unrecognized parameter \"encoder.layer.11.output.LayerNorm.bias\" in the pre-trained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(question, context)\n\u001b[1;32m     51\u001b[0m start_scores, end_scores \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39mtensor([input_ids]))\n\u001b[0;32m---> 52\u001b[0m start_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(start_scores)\n\u001b[1;32m     53\u001b[0m end_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(end_scores)\n\u001b[1;32m     54\u001b[0m predicted_answer \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_tokens_to_string(tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(input_ids[start_index:end_index\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Load the fine-tuned model's state dict\n",
    "model_path = '/home/ssarrouf/Documents/qa_output/checkpoint-10000/pytorch_model.bin'\n",
    "state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Initialize a new instance of the BERT model with the same architecture as the pre-trained model\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Modify the weights of the pre-trained model to match the architecture of the new model\n",
    "model_dict = model.state_dict()\n",
    "for name, param in state_dict.items():\n",
    "    if name.startswith('bert.'):\n",
    "        name = '.'.join(name.split('.')[1:])  # Remove the \"bert.\" prefix from the state dict keys\n",
    "        if name.endswith('.gamma'):\n",
    "            name = name[:-5] + '.weight'  # Replace \".gamma\" with \".weight\" in layer normalization parameters\n",
    "        elif name.endswith('.beta'):\n",
    "            name = name[:-4] + '.bias'  # Replace \".beta\" with \".bias\" in layer normalization parameters\n",
    "        if name in model_dict:\n",
    "            if isinstance(param, torch.nn.Parameter):\n",
    "                param = param.data\n",
    "            if model_dict[name].shape == param.shape:\n",
    "                model_dict[name] = param\n",
    "            else:\n",
    "                print(f'Parameter shape mismatch for \"{name}\": pre-trained ({param.shape}) vs. new model ({model_dict[name].shape})')\n",
    "        else:\n",
    "            print(f'Unrecognized parameter \"{name}\" in the pre-trained model')\n",
    "model.load_state_dict(model_dict)\n",
    "model.eval()\n",
    "\n",
    "# Load the SQuAD dev-v2.0 dataset\n",
    "data_path = '/home/ssarrouf/Documents/GitHub/WaterRemediationBERT/dev-v2.0.json'\n",
    "with open(data_path, 'r') as f:\n",
    "    squad_dev = json.load(f)['data']\n",
    "\n",
    "# Tokenize the input and get the predicted answer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "predictions = []\n",
    "true_answers = []\n",
    "for article in tqdm(squad_dev):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for qa in paragraph['qas']:\n",
    "            question = qa['question']\n",
    "            context = paragraph['context']\n",
    "            input_ids = tokenizer.encode(question, context)\n",
    "            start_scores, end_scores = model(torch.tensor([input_ids]))\n",
    "            start_index = torch.argmax(start_scores)\n",
    "            end_index = torch.argmax(end_scores)\n",
    "            predicted_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[start_index:end_index+1]))\n",
    "            predictions.append(predicted_answer)\n",
    "            true_answers.append(qa['answers'][0]['text'])\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "f1 = f1_score(true_answers, predictions, average='weighted')\n",
    "precision = precision_score(true_answers, predictions, average='weighted')\n",
    "recall = recall_score(true_answers, predictions, average='weighted')\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load the new data from file\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/qa_validation_dataset.json\", \"r\") as f:\n",
    "    new_data = json.load(f)\n",
    "\n",
    "# load the existing data from file\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json\", \"r\") as f:\n",
    "    existing_data = json.load(f)\n",
    "\n",
    "# append the new data to the existing data\n",
    "for item in new_data[\"data\"]:\n",
    "    for paragraph in item[\"paragraphs\"]:\n",
    "        paragraph[\"qas\"][0][\"id\"] = str(int(paragraph[\"qas\"][0][\"id\"].split(\"-\")[-1]) + 1)\n",
    "    existing_data[\"data\"].append(item)\n",
    "\n",
    "# save the updated data to file\n",
    "with open(\"updated_data.json\", \"w\") as f:\n",
    "    json.dump(existing_data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Find the index of the item with id \"241\"\n",
    "index = None\n",
    "for i, item in enumerate(data['data']):\n",
    "    if 'id' in item and item['id'] == '240':\n",
    "        index = i\n",
    "        break\n",
    "\n",
    "# Update the IDs of subsequent items\n",
    "if index is not None:\n",
    "    for item in data['data'][index:]:\n",
    "        if 'id' in item:\n",
    "            item['id'] = str(int(item['id']) + 1)\n",
    "\n",
    "# Save the updated data back to file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def reset_answer_start(data):\n",
    "    for elem in data[\"data\"]:\n",
    "        paragraphs = elem[\"paragraphs\"]\n",
    "        for paragraph in paragraphs:\n",
    "            context = paragraph[\"context\"]\n",
    "            modified_context = re.sub(' +', ' ', context)\n",
    "            modified_context = modified_context.lower()\n",
    "            qas = paragraph[\"qas\"]\n",
    "            for qa in qas:\n",
    "                answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                answer_text = re.sub(' +', ' ', answer_text)\n",
    "                answer_text = answer_text.lower()\n",
    "                modified_answer_text = ''.join(c for c in answer_text if c.isalpha())\n",
    "                modified_context_text = ''.join(c for c in modified_context if c.isalpha())\n",
    "                match = re.search(re.escape(modified_answer_text), modified_context_text)\n",
    "                if match:\n",
    "                    original_answer_start = match.start()\n",
    "                    # update answer_start to the index in the original context, accounting for removed spaces\n",
    "                    modified_answer_start = len(answer_text) - len(answer_text[:original_answer_start].replace(' ', ''))\n",
    "                    qa[\"answers\"][0][\"answer_start\"] = context.find(answer_text, modified_answer_start)\n",
    "\n",
    "\n",
    "# load the JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3_generated_predictions.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# reset answer_start values if needed\n",
    "reset_answer_start(data)\n",
    "\n",
    "# write the modified data back to a file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3_generated_predictions.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3_generated_predictions.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for elem in data[\"data\"]:\n",
    "    paragraphs = elem[\"paragraphs\"]\n",
    "    for paragraph in paragraphs:\n",
    "        context = paragraph[\"context\"]\n",
    "        modified_context = re.sub(' +', ' ', context)\n",
    "        modified_context = modified_context.lower()\n",
    "        qas = paragraph[\"qas\"]\n",
    "        for qa in qas:\n",
    "            answer_start = qa[\"answers\"][0][\"answer_start\"]\n",
    "            if answer_start == -1:\n",
    "                answer_text = qa[\"answers\"][0][\"text\"].lower().strip().replace(\"  \", \" \")\n",
    "                match = re.search(re.escape(answer_text), modified_context)\n",
    "                if match is not None:\n",
    "                    qa[\"answers\"][0][\"answer_start\"] = match.start()\n",
    "\n",
    "# write the modified data back to a file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3_generated_predictions.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "# Create a SummaryWriter object with a log directory\n",
    "writer = SummaryWriter('/home/ssarrouf/Documents/qa_finetune_output_2')\n",
    "\n",
    "for n_iter in range(100):\n",
    "    # Log the training and testing loss and accuracy\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n",
    "\n",
    "# Close the SummaryWriter object\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b43dec337adcd88a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b43dec337adcd88a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /home/ssarrouf/Documents/qa_finetune_output_2 --port 6007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4231820316.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    killall tensorboard\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "killall tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m# Compute the evaluation results\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# You can replace \"metric_name\" with the name of the metric you want to use, such as \"squad\" or \"bertscore\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m metric \u001b[39m=\u001b[39m load_metric(\u001b[39m\"\u001b[39m\u001b[39msquad\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m results \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39;49mcompute(predictions\u001b[39m=\u001b[39;49mpredictions, references\u001b[39m=\u001b[39;49mground_truth)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Print the evaluation results\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/metric.py:442\u001b[0m, in \u001b[0;36mMetric.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m compute_kwargs \u001b[39m=\u001b[39m {k: kwargs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m kwargs \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures}\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m--> 442\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_batch(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalize()\n\u001b[1;32m    445\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_file_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/metric.py:494\u001b[0m, in \u001b[0;36mMetric.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m batch \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m\"\u001b[39m: predictions, \u001b[39m\"\u001b[39m\u001b[39mreferences\u001b[39m\u001b[39m\"\u001b[39m: references, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    493\u001b[0m batch \u001b[39m=\u001b[39m {intput_name: batch[intput_name] \u001b[39mfor\u001b[39;00m intput_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures}\n\u001b[0;32m--> 494\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo\u001b[39m.\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mencode_batch(batch)\n\u001b[1;32m    495\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_writer()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/features/features.py:1827\u001b[0m, in \u001b[0;36mFeatures.encode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mfor\u001b[39;00m key, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1826\u001b[0m     column \u001b[39m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1827\u001b[0m     encoded_batch[key] \u001b[39m=\u001b[39m [encode_nested_example(\u001b[39mself\u001b[39m[key], obj) \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m column]\n\u001b[1;32m   1828\u001b[0m \u001b[39mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/features/features.py:1827\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39mfor\u001b[39;00m key, column \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1826\u001b[0m     column \u001b[39m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 1827\u001b[0m     encoded_batch[key] \u001b[39m=\u001b[39m [encode_nested_example(\u001b[39mself\u001b[39;49m[key], obj) \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m column]\n\u001b[1;32m   1828\u001b[0m \u001b[39mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/features/features.py:1212\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m level \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGot None but expected a dictionary instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1211\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m-> 1212\u001b[0m         {\n\u001b[1;32m   1213\u001b[0m             k: encode_nested_example(sub_schema, sub_obj, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m   1214\u001b[0m             \u001b[39mfor\u001b[39;00m k, (sub_schema, sub_obj) \u001b[39min\u001b[39;00m zip_dict(schema, obj)\n\u001b[1;32m   1215\u001b[0m         }\n\u001b[1;32m   1216\u001b[0m         \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m   1221\u001b[0m     sub_schema \u001b[39m=\u001b[39m schema[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/features/features.py:1212\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m level \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mGot None but expected a dictionary instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1211\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m-> 1212\u001b[0m         {\n\u001b[1;32m   1213\u001b[0m             k: encode_nested_example(sub_schema, sub_obj, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m   1214\u001b[0m             \u001b[39mfor\u001b[39;00m k, (sub_schema, sub_obj) \u001b[39min\u001b[39;00m zip_dict(schema, obj)\n\u001b[1;32m   1215\u001b[0m         }\n\u001b[1;32m   1216\u001b[0m         \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m   1221\u001b[0m     sub_schema \u001b[39m=\u001b[39m schema[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/utils/py_utils.py:302\u001b[0m, in \u001b[0;36mzip_dict\u001b[0;34m(*dicts)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Iterate over items of dictionaries grouped by their keys.\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m unique_values(itertools\u001b[39m.\u001b[39mchain(\u001b[39m*\u001b[39mdicts)):  \u001b[39m# set merge all keys\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39m# Will raise KeyError if the dict don't have the same keys\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     \u001b[39myield\u001b[39;00m key, \u001b[39mtuple\u001b[39;49m(d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m dicts)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/myenv/lib/python3.8/site-packages/datasets/utils/py_utils.py:302\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Iterate over items of dictionaries grouped by their keys.\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m unique_values(itertools\u001b[39m.\u001b[39mchain(\u001b[39m*\u001b[39mdicts)):  \u001b[39m# set merge all keys\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39m# Will raise KeyError if the dict don't have the same keys\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     \u001b[39myield\u001b[39;00m key, \u001b[39mtuple\u001b[39m(d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dicts)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_metric\n",
    "import uuid\n",
    "\n",
    "# Load the ground truth and actual prediction JSON files\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3_generated_predictions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    predictions = json.load(f)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if \"id\" not in predictions[i]:\n",
    "        predictions[i][\"id\"] = str(uuid.uuid4())\n",
    "    if \"id\" not in ground_truth[i]:\n",
    "        ground_truth[i][\"id\"] = str(uuid.uuid4())\n",
    "\n",
    "matching_ids = set([qa[\"id\"] for ex in predictions[\"data\"] for para in ex[\"paragraphs\"] for qa in para[\"qas\"]])\n",
    "for qa in ground_truth[\"data\"]:\n",
    "    if \"qas\" in qa:\n",
    "        for q in qa[\"qas\"]:\n",
    "            if \"id\" in q and q[\"id\"] not in matching_ids:\n",
    "                print(\"Question ID not found in predictions:\", q[\"id\"])\n",
    "ground_truth = [ex for ex in ground_truth[\"data\"] for para in ex[\"paragraphs\"] for qa in para[\"qas\"] if \"id\" in qa and qa[\"id\"] in matching_ids]\n",
    "predictions = [ex for ex in predictions[\"data\"] for para in ex[\"paragraphs\"] for qa in para[\"qas\"] if \"id\" in qa and qa[\"id\"] in matching_ids]\n",
    "\n",
    "# Compute the evaluation results\n",
    "# You can replace \"metric_name\" with the name of the metric you want to use, such as \"squad\" or \"bertscore\"\n",
    "metric = load_metric(\"squad\")\n",
    "results = metric.compute(predictions=predictions, references=ground_truth)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      6\u001b[0m output \u001b[39m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mv2.0\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[1;32m      9\u001b[0m         {\n\u001b[0;32m---> 10\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: data[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mparagraphs\u001b[39m\u001b[39m\"\u001b[39m: []\n\u001b[1;32m     12\u001b[0m         }\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m data[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mparagraphs\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     17\u001b[0m     output[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mparagraphs\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     18\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mqas\u001b[39m\u001b[39m\"\u001b[39m: obj[\u001b[39m\"\u001b[39m\u001b[39mqas\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     19\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m: obj[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m     })\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "output = {\n",
    "    \"version\": \"v2.0\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": data[0][\"title\"],\n",
    "            \"paragraphs\": []\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "for obj in data[0][\"paragraphs\"]:\n",
    "    output[\"data\"][0][\"paragraphs\"].append({\n",
    "        \"qas\": obj[\"qas\"],\n",
    "        \"context\": obj[\"context\"]\n",
    "    })\n",
    "\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated3_output_ground_truth.json', 'w') as f:\n",
    "    json.dump(output, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 18\u001b[0m\n\u001b[1;32m      6\u001b[0m output \u001b[39m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mv-1.1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m data:\n\u001b[1;32m     17\u001b[0m     output[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mparagraphs\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend({\n\u001b[0;32m---> 18\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mqas\u001b[39m\u001b[39m\"\u001b[39m: obj[\u001b[39m\"\u001b[39;49m\u001b[39mqas\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     19\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m: obj[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m     })\n\u001b[1;32m     22\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated3_output_ground_truth.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     23\u001b[0m     json\u001b[39m.\u001b[39mdump(output, f)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output_new_squad_finetune_qa_generated_results.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "output = {\n",
    "    \"version\": \"v-1.1\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"squad desired results\",\n",
    "            \"paragraphs\": []\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "for obj in data:\n",
    "    output[\"data\"][0][\"paragraphs\"].append({\n",
    "        \"qas\": obj[\"qas\"],\n",
    "        \"context\": obj[\"context\"]\n",
    "    })\n",
    "\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated3_output_ground_truth.json', 'w') as f:\n",
    "    json.dump(output, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from batterydataextractor.doc.text import Paragraph\n",
    "\n",
    "# Load the ground truth data\n",
    "with open('ground_truth.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract predictions for each question and context in the ground truth data\n",
    "for item in data['data']:\n",
    "    for para in item['paragraphs']:\n",
    "        for qas in para['qas']:\n",
    "            # Get the question and context text\n",
    "            question = qas['question']\n",
    "            context = para['context']\n",
    "            \n",
    "            # Use Battery Data Extractor to generate predictions\n",
    "            doc = Paragraph(context)\n",
    "            doc.add_general_models([question], confidence_threshold=0.1, self_defined=True)\n",
    "            \n",
    "            # Add the predictions to the ground truth data\n",
    "            qas['predicted_answers'] = doc.records[0].answers\n",
    "            \n",
    "# Write the updated ground truth data to a new file\n",
    "with open('battery_data_predictions.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = '/home/ssarrouf/Documents/qa_output/checkpoint-10000'  # replace with the name of your fine-tuned model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Load the contexts and questions from the input JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Define the output JSON data\n",
    "output_data = {\n",
    "    \"version\": \"v2.0\",\n",
    "    \"data\": []\n",
    "}\n",
    "\n",
    "# Loop through the data and generate predictions\n",
    "for item in data['data']:\n",
    "    title = item.get('title', '')\n",
    "    paragraphs = item.get('paragraphs', [])\n",
    "    output_paragraphs = []\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        qas = paragraph.get('qas', [])\n",
    "        context = paragraph.get('context', '')\n",
    "        output_qas = []\n",
    "\n",
    "        for qa in qas:\n",
    "            id = qa.get('id', '')\n",
    "            question = qa.get('question', '')\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "            # Generate the predictions\n",
    "            outputs = model(**inputs)\n",
    "            start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "            start_index = torch.argmax(start_scores)\n",
    "            end_index = torch.argmax(end_scores)\n",
    "            answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][start_index:end_index+1]))\n",
    "\n",
    "            # Create the output QA data\n",
    "            output_qa = {\n",
    "                \"id\": id,\n",
    "                \"question\": question,\n",
    "                \"answers\": [\n",
    "                    {\n",
    "                        \"text\": answer,\n",
    "                        \"answer_start\": context.find(answer)\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            output_qas.append(output_qa)\n",
    "\n",
    "        # Create the output paragraph data\n",
    "        output_paragraph = {\n",
    "            \"qas\": output_qas,\n",
    "            \"context\": context\n",
    "        }\n",
    "\n",
    "        output_paragraphs.append(output_paragraph)\n",
    "\n",
    "    # Create the output data for this item\n",
    "    output_item = {\n",
    "        \"title\": title,\n",
    "        \"paragraphs\": output_paragraphs\n",
    "    }\n",
    "\n",
    "    output_data['data'].append(output_item)\n",
    "\n",
    "# Save the output data to a new JSON file\n",
    "with open('output2_generated_predictions.json', 'w') as f:\n",
    "    json.dump(output_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "# Find the index of the first question with an ID greater than 240\n",
    "start_index = None\n",
    "for i in range(len(data['data'])):\n",
    "    for j in range(len(data['data'][i]['paragraphs'][0]['qas'])):\n",
    "        if int(data['data'][i]['paragraphs'][0]['qas'][j]['id']) > 240:\n",
    "            start_index = (i, j)\n",
    "            break\n",
    "    if start_index:\n",
    "        break\n",
    "\n",
    "# Modify the IDs of the subsequent questions\n",
    "current_id = 241\n",
    "if start_index:\n",
    "    for i in range(start_index[0], len(data['data'])):\n",
    "        for j in range(start_index[1], len(data['data'][i]['paragraphs'][0]['qas'])):\n",
    "            data['data'][i]['paragraphs'][0]['qas'][j]['id'] = str(current_id)\n",
    "            current_id += 1\n",
    "\n",
    "\n",
    "# Write the modified data back to the original JSON file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Find the index of the first question with ID of 240\n",
    "start_index = None\n",
    "for i in range(len(data['data'])):\n",
    "    for j in range(len(data['data'][i]['paragraphs'])):\n",
    "        for k in range(len(data['data'][i]['paragraphs'][j]['qas'])):\n",
    "            if data['data'][i]['paragraphs'][j]['qas'][k]['id'] == '240':\n",
    "                start_index = (i, j, k)\n",
    "                break\n",
    "        if start_index:\n",
    "            break\n",
    "    if start_index:\n",
    "        break\n",
    "\n",
    "if start_index is None:\n",
    "    print(f\"No question with id 240 was found\")\n",
    "    exit()\n",
    "\n",
    "# Modify the IDs of the subsequent questions\n",
    "current_id = 241\n",
    "for i in range(start_index[0], len(data['data'])):\n",
    "    for j in range(start_index[1], len(data['data'][i]['paragraphs'])):\n",
    "        for k in range(start_index[2], len(data['data'][i]['paragraphs'][j]['qas'])):\n",
    "            data['data'][i]['paragraphs'][j]['qas'][k]['id'] = str(current_id)\n",
    "            current_id += 1\n",
    "\n",
    "# Write the modified data back to the original JSON file\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_2.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(json_string)\n",
    "\n",
    "# Get the starting ID for the new questions\n",
    "starting_id = int(data[\"data\"][0][\"qas\"][0][\"id\"]) + 1\n",
    "\n",
    "# Loop through the contexts and questions to update the IDs\n",
    "for i, paragraph in enumerate(data[\"data\"]):\n",
    "    for j, qa in enumerate(paragraph[\"qas\"]):\n",
    "        if qa[\"id\"] != \"239\":\n",
    "            qa[\"id\"] = str(starting_id)\n",
    "            starting_id += 1\n",
    "\n",
    "# Convert the updated data back to JSON\n",
    "updated_json_string = json.dumps(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/output2_generated_predictions.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Find the index of the question with ID of 239\n",
    "start_index = None\n",
    "for i in range(len(data['data'])):\n",
    "    for j in range(len(data['data'][i]['paragraphs'])):\n",
    "        for k in range(len(data['data'][i]['paragraphs'][j]['qas'])):\n",
    "            if data['data'][i]['paragraphs'][j]['qas'][k]['id'] == '240':\n",
    "                start_index = (i, j, k)\n",
    "                break\n",
    "        if start_index:\n",
    "            break\n",
    "    if start_index:\n",
    "        break\n",
    "\n",
    "if start_index is None:\n",
    "    print(f\"No question with id 239 was found\")\n",
    "    exit()\n",
    "\n",
    "# Modify the IDs of the subsequent questions\n",
    "current_id = 241\n",
    "for i in range(start_index[0], len(data['data'])):\n",
    "    for j in range(start_index[1], len(data['data'][i]['paragraphs'])):\n",
    "        for k in range(start_index[2], len(data['data'][i]['paragraphs'][j]['qas'])):\n",
    "            if data['data'][i]['paragraphs'][j]['qas'][k]['id'] != '240':\n",
    "                data['data'][i]['paragraphs'][j]['qas'][k]['id'] = str(current_id)\n",
    "                current_id += 1\n",
    "\n",
    "# Write the modified data back to the original JSON file\n",
    "with open(\"/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/updated_data_3_generated_predictions.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 09:37:27.369632: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 09:37:28.230520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"/home/ssarrouf/Documents/qa_output/checkpoint-10000\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "{'input_ids': tensor([[  101,  1106,  2292,  1225,  1103, 16946, 12477,  1616,  9273,  2845,\n",
      "          1107,  8109,  1107, 25338,  2149,  4704,   175, 10555,   136,   102,\n",
      "          6645,  1193,   117,  1103,  1278,  1144,   170,  5855, 14084,  1596,\n",
      "          1959,   119, 10343,  1103,  1514,  1459,   112,   188,  2284, 10945,\n",
      "          1110,   170,  5404,  5921,  1104,  1103, 16946, 12477,  1616,   119,\n",
      "          2411,  1107,  1524,  1104,  1103,  1514,  1459,  1105,  4749,  1122,\n",
      "           117,  1110,   170,  7335,  5921,  1104, 22572, 12937,  1114,  1739,\n",
      "          1146, 14089,  5591,  1114,  1103,  7051,   107,  1396,  2605,  1566,\n",
      "          8050,  1143,   184,  1306,  3965,   107,   119,  1397,  1106,  1103,\n",
      "          1514,  1459,  1110,  1103,   171, 17506,  9538,  1104,  1103,  8854,\n",
      "          1762,   119,  2411,  1481,  1103,   171, 17506,  9538,  1110,  1103,\n",
      "           176, 10595,  2430,   117,   170, 12477,  5476,  1282,  1104,  8070,\n",
      "          1105,  9284,   119,  1122,  1110,   170, 16498,  1104,  1103,   176,\n",
      "         10595,  2430,  1120, 25338,  2149,  4704,   117,   175, 10555,  1187,\n",
      "          1103, 16946, 12477,  1616, 25153,  1193,  1691,  1106, 10916,  1129,\n",
      "         11782, 26514,  1566,  1177, 25422, 13149,  1107,  8109,   119,  1120,\n",
      "          1103,  1322,  1104,  1103,  1514,  2797,   113,  1105,  1107,   170,\n",
      "          2904,  1413,  1115,  8200,  1194,   124, 11739,  1105,  1103,  2284,\n",
      "         10945,   114,   117,  1110,   170,  3014,   117,  2030,  2576,  5921,\n",
      "          1104, 12477,  1616,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(start_scores))\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(end_scores))\n\u001b[0;32m---> 41\u001b[0m answer_start \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(start_scores)\n\u001b[1;32m     42\u001b[0m answer_end \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(end_scores) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[39m# Get the tokens corresponding to the best start and end positions\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the SQuAD ground truth file\n",
    "with open('/home/ssarrouf/Documents/GitHub/WaterRemediationParser/performance_evaluation/train-v1.1.json', 'r') as f:\n",
    "    squad_data = json.load(f)\n",
    "\n",
    "# Initialize an empty list for the predictions\n",
    "predictions = []\n",
    "\n",
    "# Load your tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/ssarrouf/Documents/qa_output/checkpoint-10000\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"/home/ssarrouf/Documents/qa_output/checkpoint-10000\")\n",
    "\n",
    "# Check the model's configuration\n",
    "print(model.config)\n",
    "\n",
    "# Loop over each article in the SQuAD ground truth file\n",
    "for article in squad_data['data']:\n",
    "    # Initialize an empty list for the paragraphs in the article\n",
    "    paragraphs = []\n",
    "\n",
    "    # Loop over each paragraph in the article\n",
    "    for paragraph in article['paragraphs']:\n",
    "        # Initialize an empty list for the QA pairs in the paragraph\n",
    "        qas = []\n",
    "\n",
    "        # Loop over each QA pair in the paragraph\n",
    "        for qa in paragraph['qas']:\n",
    "            # Tokenize the question and context\n",
    "            question = qa['question']\n",
    "            context = paragraph['context']\n",
    "            inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n",
    "            print(inputs)\n",
    "\n",
    "            # Generate the model's prediction\n",
    "            outputs = model(**inputs)\n",
    "            start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "            print(type(start_scores))\n",
    "            print(type(end_scores))\n",
    "            answer_start = torch.argmax(start_scores)\n",
    "            answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "\n",
    "            # Get the tokens corresponding to the best start and end positions\n",
    "            answer_tokens = inputs[\"input_ids\"][0][answer_start:answer_end]\n",
    "            answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "            # Create the answer dictionary\n",
    "            answer_dict = {\n",
    "                'text': answer,\n",
    "                'answer_start': answer_start.item()\n",
    "            }\n",
    "\n",
    "            # Create the QA dictionary\n",
    "            qa_dict = {\n",
    "                'question': qa['question'],\n",
    "                'id': qa['id'],\n",
    "                'answers': [answer_dict]\n",
    "            }\n",
    "\n",
    "            # Add the QA dictionary to the list of QA pairs\n",
    "            qas.append(qa_dict)\n",
    "\n",
    "        # Create the paragraph dictionary\n",
    "        paragraph_dict = {\n",
    "            'context': paragraph['context'],\n",
    "            'qas': qas\n",
    "        }\n",
    "\n",
    "        # Add the paragraph dictionary to the list of paragraphs\n",
    "        paragraphs.append(paragraph_dict)\n",
    "\n",
    "    # Create the article dictionary\n",
    "    article_dict = {\n",
    "        'title': article['title'],\n",
    "        'paragraphs': paragraphs\n",
    "    }\n",
    "\n",
    "    # Add the article dictionary to the list of articles\n",
    "    predictions.append(article_dict)\n",
    "\n",
    "# Save the predictions to a JSON file\n",
    "with open('squad_train_v1.1_predictions.json', 'w') as f:\n",
    "    json.dump({'data': predictions}, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c5e1d0e4655455a9974ddc459a19ce2e2896d6c4aa821bb710c76b0241f7028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
